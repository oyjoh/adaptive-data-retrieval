{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GEBCOâ€™s Gridded Bathymetry Data\n",
    "source: Local\n",
    "\n",
    "Size: 7.5GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from app.dataprocessing.data_handler import DataHandler\n",
    "from app.dataprocessing.benchmark import plt_img, save_simple_img, demo_plt_img\n",
    "from app.datastructures.datastructure_interface import get_ipyleaflet_bounds\n",
    "from app.dataprocessing.benchmark import Stopwatch\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup(c_size, struct):\n",
    "    data_handler = DataHandler()\n",
    "    data_handler.set_max_chunk_size(c_size)\n",
    "\n",
    "    file_path = \"app/externalresources/datasets/GEBCO_2022_sub_ice_topo.nc\"\n",
    "\n",
    "    # data_handler.set_local_netcdf_reader(file_path, 'KDTree')\n",
    "    data_handler.set_local_netcdf_reader(file_path, struct)\n",
    "\n",
    "    print(f\"Data structure in use: {data_handler.data_structure}\")\n",
    "\n",
    "    initial_ds, bnds, node = data_handler.get_initial_ds()\n",
    "    # initial_ds.to_netcdf(\"panoplydemo.nc\")\n",
    "    data_variable = \"elevation\"\n",
    "    img_format = \"png\"\n",
    "\n",
    "    arr = initial_ds[data_variable].isel(\n",
    "        {\n",
    "            x: 0\n",
    "            for x in initial_ds.dims\n",
    "            if x not in [\"lat\", \"lon\", \"latitude\", \"longitude\"]\n",
    "        }\n",
    "    )\n",
    "    vmin_glob = arr.min().values\n",
    "    vmax_glob = arr.max().values\n",
    "\n",
    "    bounds = get_ipyleaflet_bounds(initial_ds)\n",
    "    return data_handler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_1 = ((-90, 90), (-180, 180))\n",
    "query_2 = ((-74.09, -3.78), (-155.45, -56.49))\n",
    "query_3 = ((-40.46, -5.30), (-68.70, -19.21))\n",
    "query_4 = ((-9.20, -0.41), (-88.42, -76.05))\n",
    "\n",
    "sequence = [query_1, query_2, query_3, query_4]\n",
    "sizes = [10, 50, 100]\n",
    "structs = [\"QuadTree\", \"KDTree\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "QuadTree with chunksize: 10\n",
      "Finished 'Loading dataset' in 0.1108 seconds\n",
      "Finished 'Creating data structure' in 32.1814 seconds\n",
      "Data structure in use: QuadTree with 1024 chunks at lowest level of max chunk size 10MB\n",
      "--- step 0 ---\n",
      "query bounds: ((-90, 90), (-180, 180))\n",
      "--- step 1 ---\n",
      "query bounds: ((-74.09, -3.78), (-155.45, -56.49))\n",
      "--- step 2 ---\n",
      "query bounds: ((-40.46, -5.3), (-68.7, -19.21))\n",
      "--- step 3 ---\n",
      "query bounds: ((-9.2, -0.41), (-88.42, -76.05))\n",
      "----------------------------\n",
      "QuadTree with chunksize: 50\n",
      "Finished 'Loading dataset' in 0.0094 seconds\n",
      "Finished 'Creating data structure' in 4.7907 seconds\n",
      "Data structure in use: QuadTree with 256 chunks at lowest level of max chunk size 50MB\n",
      "--- step 0 ---\n",
      "query bounds: ((-90, 90), (-180, 180))\n",
      "--- step 1 ---\n",
      "query bounds: ((-74.09, -3.78), (-155.45, -56.49))\n",
      "--- step 2 ---\n",
      "query bounds: ((-40.46, -5.3), (-68.7, -19.21))\n",
      "--- step 3 ---\n",
      "query bounds: ((-9.2, -0.41), (-88.42, -76.05))\n",
      "----------------------------\n",
      "QuadTree with chunksize: 100\n",
      "Finished 'Loading dataset' in 0.0092 seconds\n",
      "Finished 'Creating data structure' in 4.4610 seconds\n",
      "Data structure in use: QuadTree with 256 chunks at lowest level of max chunk size 100MB\n",
      "--- step 0 ---\n",
      "query bounds: ((-90, 90), (-180, 180))\n",
      "--- step 1 ---\n",
      "query bounds: ((-74.09, -3.78), (-155.45, -56.49))\n",
      "--- step 2 ---\n",
      "query bounds: ((-40.46, -5.3), (-68.7, -19.21))\n",
      "--- step 3 ---\n",
      "query bounds: ((-9.2, -0.41), (-88.42, -76.05))\n",
      "----------------------------\n",
      "KDTree with chunksize: 10\n",
      "Finished 'Loading dataset' in 0.0169 seconds\n",
      "Finished 'Creating data structure' in 1.1319 seconds\n",
      "Data structure in use: KDTree with 1024 leaf nodes of maximum size 10MB\n",
      "--- step 0 ---\n",
      "query bounds: ((-90, 90), (-180, 180))\n",
      "--- step 1 ---\n",
      "query bounds: ((-74.09, -3.78), (-155.45, -56.49))\n",
      "--- step 2 ---\n",
      "query bounds: ((-40.46, -5.3), (-68.7, -19.21))\n",
      "--- step 3 ---\n",
      "query bounds: ((-9.2, -0.41), (-88.42, -76.05))\n",
      "----------------------------\n",
      "KDTree with chunksize: 50\n",
      "Finished 'Loading dataset' in 0.0089 seconds\n",
      "Finished 'Creating data structure' in 0.2203 seconds\n",
      "Data structure in use: KDTree with 256 leaf nodes of maximum size 50MB\n",
      "--- step 0 ---\n",
      "query bounds: ((-90, 90), (-180, 180))\n",
      "--- step 1 ---\n",
      "query bounds: ((-74.09, -3.78), (-155.45, -56.49))\n",
      "--- step 2 ---\n",
      "query bounds: ((-40.46, -5.3), (-68.7, -19.21))\n",
      "--- step 3 ---\n",
      "query bounds: ((-9.2, -0.41), (-88.42, -76.05))\n",
      "----------------------------\n",
      "KDTree with chunksize: 100\n",
      "Finished 'Loading dataset' in 0.0067 seconds\n",
      "Finished 'Creating data structure' in 0.2033 seconds\n",
      "Data structure in use: KDTree with 128 leaf nodes of maximum size 100MB\n",
      "--- step 0 ---\n",
      "query bounds: ((-90, 90), (-180, 180))\n",
      "--- step 1 ---\n",
      "query bounds: ((-74.09, -3.78), (-155.45, -56.49))\n",
      "--- step 2 ---\n",
      "query bounds: ((-40.46, -5.3), (-68.7, -19.21))\n",
      "--- step 3 ---\n",
      "query bounds: ((-9.2, -0.41), (-88.42, -76.05))\n"
     ]
    }
   ],
   "source": [
    "overleaf_meta_log = []\n",
    "overleaf_data_log = []\n",
    "\n",
    "for struct in structs:\n",
    "    for size in sizes:\n",
    "        print(f\"----------------------------\")\n",
    "        print(f\"{struct} with chunksize: {size}\")\n",
    "        overleaf_meta_log.append((struct, size))\n",
    "        data_handler = setup(size, struct)\n",
    "        for idx, s in enumerate(sequence):\n",
    "            print(f\"--- step {idx} ---\")\n",
    "            print(f\"query bounds: {s}\")\n",
    "            timer = Stopwatch()\n",
    "\n",
    "            # average time over 10 runs\n",
    "            total_time = 0\n",
    "            for _ in range(10):\n",
    "                timer.start(\"Fetch netCDF chunk\")\n",
    "                file_name, bounds, node = data_handler.request_data_netcdf(\n",
    "                    s, return_xr_chunk=True\n",
    "                )\n",
    "                fetch_time = timer.alt_stop()\n",
    "                total_time += fetch_time\n",
    "            avg_time = f\"{total_time/10:0.4f}\"\n",
    "\n",
    "            # ref (-89.99, 89.88), (-179.99, 179.88) & 0.14\\% & 9.83 & 1.0214s \\\\\n",
    "            p_bounds = f\"({bounds[0][0]:.2f}, {bounds[0][1]:.2f}), ({bounds[1][0]:.2f}, {bounds[1][1]:.2f})\"\n",
    "            #overleaf_log.append(\n",
    "            #    f\"{p_bounds} & {data_handler.get_node_resolution(node):.2f}\\% & {data_handler.get_file_size_MB(file_name):.2f} & {avg_time}\"\n",
    "            #)\n",
    "            overleaf_data_log.append((p_bounds, f\"{data_handler.get_node_resolution(node):.2f}\", f\"{data_handler.get_file_size_MB(file_name):.2f}\", avg_time))\n",
    "\n",
    "            \"\"\"            print(f\"closest chunk bounds: {bounds}\")\n",
    "            print(\n",
    "                f\"Chunk resolution: {data_handler.get_node_resolution(node):.2f}%, File size: {data_handler.get_file_size_MB(file_name):.2f} MB\"\n",
    "            )\n",
    "            print(fetch_time)\n",
    "            \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\hline\n",
      "\\multicolumn{5}{|c|}{QuadTree(10)} \\\\\n",
      "\\hline\n",
      "No. & Response bounds & Resolution & File size(MB) & Time(10 run avg.) \\\\\n",
      "\\hline\n",
      "1 & (-90.00, 89.89), (-180.00, 179.89) & 0.14\\% & 9.83 & 1.0244 \\\\\n",
      "2 & (-90.00, -0.05), (-180.00, -0.04) & 0.51\\% & 9.14 & 0.6265 \\\\\n",
      "3 & (-45.00, -0.02), (-90.00, -0.02) & 2.04\\% & 9.14 & 0.2040 \\\\\n",
      "4 & (-11.25, -0.01), (-90.00, -67.51) & 25.00\\% & 7.01 & 0.1498 \\\\\n",
      "\\hline\n",
      "\\multicolumn{5}{c}{} \\\\\n",
      "\\hline\n",
      "\\multicolumn{5}{|c|}{QuadTree(50)} \\\\\n",
      "\\hline\n",
      "No. & Response bounds & Resolution & File size(MB) & Time(10 run avg.) \\\\\n",
      "\\hline\n",
      "1 & (-90.00, 89.95), (-180.00, 179.95) & 0.69\\% & 49.55 & 2.5440 \\\\\n",
      "2 & (-90.00, -0.02), (-180.00, -0.02) & 2.78\\% & 49.55 & 2.5535 \\\\\n",
      "3 & (-45.00, -0.01), (-90.00, -0.01) & 11.11\\% & 49.55 & 0.8051 \\\\\n",
      "4 & (-11.25, -0.00), (-90.00, -67.50) & 100.00\\% & 27.90 & 0.1221 \\\\\n",
      "\\hline\n",
      "\\multicolumn{5}{c}{} \\\\\n",
      "\\hline\n",
      "\\multicolumn{5}{|c|}{QuadTree(100)} \\\\\n",
      "\\hline\n",
      "No. & Response bounds & Resolution & File size(MB) & Time(10 run avg.) \\\\\n",
      "\\hline\n",
      "1 & (-90.00, 89.96), (-180.00, 179.96) & 1.23\\% & 88.03 & 3.6831 \\\\\n",
      "2 & (-90.00, -0.02), (-180.00, -0.02) & 4.00\\% & 71.32 & 3.1631 \\\\\n",
      "3 & (-45.00, -0.01), (-90.00, -0.01) & 11.11\\% & 49.55 & 1.5910 \\\\\n",
      "4 & (-11.25, -0.00), (-90.00, -67.50) & 100.00\\% & 27.90 & 0.1308 \\\\\n",
      "\\hline\n",
      "\\multicolumn{5}{c}{} \\\\\n",
      "\\hline\n",
      "\\multicolumn{5}{|c|}{KDTree(10)} \\\\\n",
      "\\hline\n",
      "No. & Response bounds & Resolution & File size(MB) & Time(10 run avg.) \\\\\n",
      "\\hline\n",
      "1 & (-90.00, 89.89), (-180.00, 179.89) & 0.14\\% & 9.83 & 0.9945 \\\\\n",
      "2 & (-90.00, 89.95), (-180.00, -0.05) & 0.28\\% & 9.92 & 1.3022 \\\\\n",
      "3 & (-90.00, -0.04), (-90.00, -0.04) & 1.00\\% & 8.96 & 0.2238 \\\\\n",
      "4 & (-22.50, -0.01), (-90.00, -67.51) & 11.11\\% & 6.23 & 0.1680 \\\\\n",
      "\\hline\n",
      "\\multicolumn{5}{c}{} \\\\\n",
      "\\hline\n",
      "\\multicolumn{5}{|c|}{KDTree(50)} \\\\\n",
      "\\hline\n",
      "No. & Response bounds & Resolution & File size(MB) & Time(10 run avg.) \\\\\n",
      "\\hline\n",
      "1 & (-90.00, 89.95), (-180.00, 179.95) & 0.69\\% & 49.55 & 2.6307 \\\\\n",
      "2 & (-90.00, 89.96), (-180.00, -0.04) & 1.23\\% & 44.04 & 3.1133 \\\\\n",
      "3 & (-90.00, -0.02), (-90.00, -0.02) & 4.00\\% & 35.69 & 0.9093 \\\\\n",
      "4 & (-22.50, -0.01), (-90.00, -67.51) & 25.00\\% & 13.97 & 0.3119 \\\\\n",
      "\\hline\n",
      "\\multicolumn{5}{c}{} \\\\\n",
      "\\hline\n",
      "\\multicolumn{5}{|c|}{KDTree(100)} \\\\\n",
      "\\hline\n",
      "No. & Response bounds & Resolution & File size(MB) & Time(10 run avg.) \\\\\n",
      "\\hline\n",
      "1 & (-90.00, 89.96), (-180.00, 179.96) & 1.23\\% & 88.03 & 3.7898 \\\\\n",
      "2 & (-90.00, 89.98), (-180.00, -0.02) & 2.78\\% & 99.01 & 5.3120 \\\\\n",
      "3 & (-90.00, -0.01), (-90.00, -0.01) & 11.11\\% & 99.01 & 3.5364 \\\\\n",
      "4 & (-22.50, -0.00), (-90.00, -67.50) & 100.00\\% & 55.73 & 1.3264 \\\\\n",
      "\\hline\n",
      "\\multicolumn{5}{c}{} \\\\\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    \\hline\n",
    "     \\multicolumn{4}{|c|}{QuadTree(10MB)} \\\\\n",
    "     \\hline\n",
    "     No. & Response bounds & Resolution & File size(MB) & Computation time(10 run avg.) \\\\\n",
    "     \\hline\n",
    "     1 & (-90.00, 89.89), (-180.00, 179.89) & 0.14\\% & 9.83 & 0.1966 \\\\\n",
    "     2 & (-90.00, -0.05), (-180.00, -0.04) & 0.51\\% & 9.14 & 0.2393 \\\\\n",
    "     3 & (-45.00, -0.02), (-90.00, -0.02) & 2.04\\% & 9.14 & 0.1887 \\\\\n",
    "     4 & (-11.25, -0.01), (-90.00, -67.51) & 25.00\\% & 7.01 & 0.1569 \\\\\n",
    "     \\hline\n",
    "     \\multicolumn{4}{c}{} \\\\\n",
    "\"\"\"\n",
    "\n",
    "idx = 0\n",
    "\n",
    "for st, sz in overleaf_meta_log:\n",
    "    print(\"\\hline\")\n",
    "    print(f\"\\multicolumn{{5}}{{|c|}}{{{st}({sz})}} \\\\\\\\\")\n",
    "    print(\"\\hline\")\n",
    "    print(\n",
    "        \"No. & Response bounds & Resolution & File size(MB) & Time(10 run avg.) \\\\\\\\\"\n",
    "    )\n",
    "    print(\"\\hline\")\n",
    "    for i in range(1, 5):\n",
    "        print(\n",
    "            f\"{i} & {overleaf_data_log[idx][0]} & {overleaf_data_log[idx][1]}\\% & {overleaf_data_log[idx][2]} & {overleaf_data_log[idx][3]} \\\\\\\\\"\n",
    "        )\n",
    "        idx += 1\n",
    "    print(\"\\hline\")\n",
    "    print(f\"\\multicolumn{{5}}{{c}}{{}} \\\\\\\\\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('master-app')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aebbdfc6aa06eaa162ce0fe2477883455d1cd47ed4782f83b429bbd98a6e3fd1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
